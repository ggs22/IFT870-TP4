{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TP4_depart\n",
    "## IFT870/BIN710 Hiver 2021\n",
    "\n",
    "### Mathieu Lussier (LUSM1202)\n",
    "### Gabriel Gibeau Sanchez (GIBG2501)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.neighbors import  KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from itertools import product\n",
    "from re import finditer\n",
    "\n",
    "# for printing variables in a markdown cell\n",
    "from IPython.display import Markdown as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(395, 2)"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP4_data_file = \"RNA_orignal.csv\"\n",
    "TP4_data = pd.read_csv(TP4_data_file,index_col=0)\n",
    "TP4_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                                                 sequence  \\\nid                                                                          \nAF093014.1/662-809      CACUUUAAGUAAUGGAUGUCUUGGUUCUCAUAACGAUGAAGGACGC...   \nM14649.1/2015-2169      AACUUUCAGCGACGGAUGUCUCGGCUCGAACAACGAUGAAGGGCGC...   \nX53361.2/1206-1368      ACCUGUUGUGGUGGAUGUCUUGGCCCAGGUUCUGAGGAAGGACACA...   \nM86760.1/218-371        AACUUUCAGCAAUGGAUCUCUUGGUUCCCGCGUCGAUGAAGAACGU...   \nX00601.1/3997-4154      AAGCAUAAACGGUGAAUACCUCGACUCCUAAAUCGAUGAAGACCGU...   \nU48228.1/7-166          CAAUCUUAACGAUGGAUGUCUUGGUUCCUAUAGCGAUGAAGGCCGC...   \nU58510.1/2022-2198      AACCCUAGUGAUGGAUGUCUAGGCUCCCGUAUCGAUGAAGAACGUA...   \nAL049755.2/30863-31016  AACUUUCAGCAACGGAUCUCUUGGCUCUCGCAUCGAUGAAGAACGC...   \nU13369.1/6624-6776      GACUCUUAGCGGUGGAUCACUCGGCUCGUGCGUCGAUGAAGAACGC...   \nV01159.1/185-331        ACCGUUGGGCGAUGGAUUGCUUGGUGCCUGCUUCGACGAAGAGCGC...   \n\n                         classe  \nid                               \nAF093014.1/662-809      RF00002  \nM14649.1/2015-2169      RF00002  \nX53361.2/1206-1368      RF00002  \nM86760.1/218-371        RF00002  \nX00601.1/3997-4154      RF00002  \nU48228.1/7-166          RF00002  \nU58510.1/2022-2198      RF00002  \nAL049755.2/30863-31016  RF00002  \nU13369.1/6624-6776      RF00002  \nV01159.1/185-331        RF00002  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>sequence</th>\n      <th>classe</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>AF093014.1/662-809</th>\n      <td>CACUUUAAGUAAUGGAUGUCUUGGUUCUCAUAACGAUGAAGGACGC...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>M14649.1/2015-2169</th>\n      <td>AACUUUCAGCGACGGAUGUCUCGGCUCGAACAACGAUGAAGGGCGC...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>X53361.2/1206-1368</th>\n      <td>ACCUGUUGUGGUGGAUGUCUUGGCCCAGGUUCUGAGGAAGGACACA...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>M86760.1/218-371</th>\n      <td>AACUUUCAGCAAUGGAUCUCUUGGUUCCCGCGUCGAUGAAGAACGU...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>X00601.1/3997-4154</th>\n      <td>AAGCAUAAACGGUGAAUACCUCGACUCCUAAAUCGAUGAAGACCGU...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>U48228.1/7-166</th>\n      <td>CAAUCUUAACGAUGGAUGUCUUGGUUCCUAUAGCGAUGAAGGCCGC...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>U58510.1/2022-2198</th>\n      <td>AACCCUAGUGAUGGAUGUCUAGGCUCCCGUAUCGAUGAAGAACGUA...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>AL049755.2/30863-31016</th>\n      <td>AACUUUCAGCAACGGAUCUCUUGGCUCUCGCAUCGAUGAAGAACGC...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>U13369.1/6624-6776</th>\n      <td>GACUCUUAGCGGUGGAUCACUCGGCUCGUGCGUCGAUGAAGAACGC...</td>\n      <td>RF00002</td>\n    </tr>\n    <tr>\n      <th>V01159.1/185-331</th>\n      <td>ACCGUUGGGCGAUGGAUUGCUUGGUGCCUGCUUCGACGAAGAGCGC...</td>\n      <td>RF00002</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TP4_data[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q1\n",
    "## a)\n",
    "Un examen des données initiales revèle que les entrées dont la classes est absente contiennent en fait la classe dans la\n",
    "colonne \"sequence\", concaténée à la valeur de séquence génétique mais séparée par une virgule. Ce puisque les champs du\n",
    "fichier sont contenus entre des guillements doubles, mais pour ces entrées un guillemet ouvrant au début de la séquence génétique\n",
    "ne trouve pas son homologue fermant (il devrait être à la fin de la séquence) ce qui fait en sorte que la virgule est vue\n",
    "comme un simple caractère de ponctuation, au lieu de servir de séparateur pour le format CSV.\n",
    "\n",
    "Pour remédier à ce problème, nous utilisons les fonctions de la classe $\\textit{string}$ et nous sauvegardons le\n",
    "$\\textit{DataFrame}$ corrigé dans un nouveau fichier CSV intitulé \"RNA.csv\"."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "# Get indexes for which the entries have no classe\n",
    "na_indexes = TP4_data['classe'].isna()\n",
    "\n",
    "data = TP4_data.copy()\n",
    "\n",
    "# Get missing classes & cleaned sequences\n",
    "split_vals = TP4_data.loc[na_indexes, 'sequence'].str.split(pat='[,\"]', expand=True)\n",
    "data.loc[na_indexes, 'classe'] = split_vals.iloc[:, 1]\n",
    "data.loc[na_indexes, 'sequence'] = split_vals.iloc[:, 0]\n",
    "\n",
    "# Save cleaned data\n",
    "data.to_csv('RNA.csv')\n",
    "\n",
    "# We'll free up unused variables to keep our dev space uncluttered\n",
    "del split_vals\n",
    "del na_indexes"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b)\n",
    "\n",
    "Il y a 12 classes dont la répartition est donnée dans la cellule de code suivante:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il y a 12 classes\n",
      "La classe RF00008 contient 54 entrées\n",
      "La classe RF00004 contient 51 entrées\n",
      "La classe RF00017 contient 49 entrées\n",
      "La classe RF00002 contient 46 entrées\n",
      "La classe RF00003 contient 42 entrées\n",
      "La classe RF00023 contient 36 entrées\n",
      "La classe RF00015 contient 25 entrées\n",
      "La classe RF00024 contient 24 entrées\n",
      "La classe RF00011 contient 19 entrées\n",
      "La classe RF00012 contient 17 entrées\n",
      "La classe RF00019 contient 16 entrées\n",
      "La classe RF00025 contient 16 entrées\n"
     ]
    }
   ],
   "source": [
    "# Ceckout unique classes values and instances number for each classe\n",
    "print(f'Il y a {data.classe.unique().shape[0]} classes')\n",
    "for ix, cls in enumerate(data.classe.value_counts().index):\n",
    "    print(f'La classe {cls} contient {data.classe.value_counts()[ix]} entrées')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## c)\n",
    "\n",
    "Ici nous balançons le nombre de données en se défaussant des instances excédant le nombre minimal"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le nombre minimum d'instance d'une classe est 16 pour la classe:\n",
      "['RF00019' 'RF00025']\n",
      "Après traitement, les classes contiennent maintenant 16 instance chacune:\n",
      "La classe RF00012 contient 16 entrées\n",
      "La classe RF00025 contient 16 entrées\n",
      "La classe RF00003 contient 16 entrées\n",
      "La classe RF00023 contient 16 entrées\n",
      "La classe RF00015 contient 16 entrées\n",
      "La classe RF00011 contient 16 entrées\n",
      "La classe RF00008 contient 16 entrées\n",
      "La classe RF00019 contient 16 entrées\n",
      "La classe RF00002 contient 16 entrées\n",
      "La classe RF00024 contient 16 entrées\n",
      "La classe RF00004 contient 16 entrées\n",
      "La classe RF00017 contient 16 entrées\n"
     ]
    }
   ],
   "source": [
    "# Fint out the minimum instances number\n",
    "classes_rep = data.classe.value_counts()\n",
    "print(f'Le nombre minimum d\\'instance d\\'une classe est {classes_rep.min()} pour la classe:\\n'\n",
    "      f'{classes_rep[classes_rep == classes_rep.min()].index.values}')\n",
    "\n",
    "cut_off = classes_rep.min()\n",
    "\n",
    "# Trim off exceding instances\n",
    "for cls in classes_rep.index:\n",
    "    indexes_to_drop = data[data['classe'] == cls].index\n",
    "    if indexes_to_drop.shape[0] > cut_off:\n",
    "        data.drop(index=indexes_to_drop[16:], axis=0, inplace=True)\n",
    "\n",
    "print(f'Après traitement, les classes contiennent maintenant {cut_off} instance chacune:')\n",
    "for ix, cls in enumerate(data.classe.value_counts().index):\n",
    "    print(f'La classe {cls} contient {data.classe.value_counts()[ix]} entrées')\n",
    "\n",
    "del classes_rep\n",
    "del cut_off"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q2\n",
    "## a)\n",
    "Ici nous ajoutons une colonne à notre $\\textit{dataframe}$ pour le nouvel attribut \"longueur\". Nous allons également encoder\n",
    "les classes en format numérique pour pouvoir calculer aisément la justesse des prédictions faites par notre modèle de\n",
    "$\\textit{K-Nearest-Neighbors}$."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Le score de prédiction est: 0.717948717948718\n",
      "1     4\n",
      "3     3\n",
      "5     3\n",
      "6     3\n",
      "7     3\n",
      "10    3\n",
      "2     2\n",
      "4     2\n",
      "11    2\n",
      "0     1\n",
      "8     1\n",
      "9     1\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ggibeau/.local/lib/python3.8/site-packages/sklearn/neighbors/_classification.py:179: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  return self._fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# add longueur column\n",
    "data['longueur'] = data['sequence'].str.len().values\n",
    "\n",
    "# Encode classes labels to numerical values\n",
    "lencoder = LabelEncoder()\n",
    "data['encoded_classe'] = lencoder.fit_transform(data['classe'].values)\n",
    "\n",
    "# Prepare training/test data, train and predict\n",
    "X_train, X_test, y_train, y_test = train_test_split(data['longueur'].values,\n",
    "                                                    data['encoded_classe'].values,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=1)\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X=X_train.reshape(-1, 1), y=y_train.reshape(-1, 1))\n",
    "\n",
    "predictions = knn.predict(X=X_test.reshape(-1, 1))\n",
    "\n",
    "# Get the indexes of the wrong predictions\n",
    "wrong_indexes = predictions-y_test != 0\n",
    "\n",
    "# Print predictions accuracy\n",
    "print(f'Le score de prédiction est: {(y_test.shape[0] - wrong_indexes.sum())/y_test.shape[0]}')\n",
    "\n",
    "# Get correct prediction to determine which classes are most easily predicted based on sequence length\n",
    "right_preds = y_test[~wrong_indexes]\n",
    "\n",
    "# Get the 5 most frequent classes that are rightfully predicted\n",
    "print(pd.Series(right_preds).value_counts())\n",
    "fclasses = lencoder.inverse_transform(pd.Series(right_preds).value_counts()[0:5].index)\n",
    "md(f'Selon ce qu\\'on constate, les classe les mieux prédites avec le'+ r' $\\textit{KNN}$ basé sur la longueur de la séquence '\n",
    "   f'sont {fclasses}')\n",
    "\n",
    "# lets drop the five most easily predicted classes\n",
    "for cls in fclasses:\n",
    "    data.drop(index=data[data['classe'] == cls].index, axis=0, inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## b) k-mers\n",
    "\n",
    "Dans un premier temps, il nous faut trouver toutes les permutations, incluant les répétitions, des nucléotides de l'ARN:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "list of 1-mer\n",
      "A\n",
      "C\n",
      "G\n",
      "U\n",
      "list of 2-mer\n",
      "AA\n",
      "AC\n",
      "AG\n",
      "AU\n",
      "CA\n",
      "CC\n",
      "CG\n",
      "CU\n",
      "GA\n",
      "GC\n",
      "GG\n",
      "GU\n",
      "UA\n",
      "UC\n",
      "UG\n",
      "UU\n",
      "list of 3-mer\n",
      "AAA\n",
      "AAC\n",
      "AAG\n",
      "AAU\n",
      "ACA\n",
      "ACC\n",
      "ACG\n",
      "ACU\n",
      "AGA\n",
      "AGC\n",
      "AGG\n",
      "AGU\n",
      "AUA\n",
      "AUC\n",
      "AUG\n",
      "AUU\n",
      "CAA\n",
      "CAC\n",
      "CAG\n",
      "CAU\n",
      "CCA\n",
      "CCC\n",
      "CCG\n",
      "CCU\n",
      "CGA\n",
      "CGC\n",
      "CGG\n",
      "CGU\n",
      "CUA\n",
      "CUC\n",
      "CUG\n",
      "CUU\n",
      "GAA\n",
      "GAC\n",
      "GAG\n",
      "GAU\n",
      "GCA\n",
      "GCC\n",
      "GCG\n",
      "GCU\n",
      "GGA\n",
      "GGC\n",
      "GGG\n",
      "GGU\n",
      "GUA\n",
      "GUC\n",
      "GUG\n",
      "GUU\n",
      "UAA\n",
      "UAC\n",
      "UAG\n",
      "UAU\n",
      "UCA\n",
      "UCC\n",
      "UCG\n",
      "UCU\n",
      "UGA\n",
      "UGC\n",
      "UGG\n",
      "UGU\n",
      "UUA\n",
      "UUC\n",
      "UUG\n",
      "UUU\n",
      "list of 4-mer\n",
      "AAAA\n",
      "AAAC\n",
      "AAAG\n",
      "AAAU\n",
      "AACA\n",
      "AACC\n",
      "AACG\n",
      "AACU\n",
      "AAGA\n",
      "AAGC\n",
      "AAGG\n",
      "AAGU\n",
      "AAUA\n",
      "AAUC\n",
      "AAUG\n",
      "AAUU\n",
      "ACAA\n",
      "ACAC\n",
      "ACAG\n",
      "ACAU\n",
      "ACCA\n",
      "ACCC\n",
      "ACCG\n",
      "ACCU\n",
      "ACGA\n",
      "ACGC\n",
      "ACGG\n",
      "ACGU\n",
      "ACUA\n",
      "ACUC\n",
      "ACUG\n",
      "ACUU\n",
      "AGAA\n",
      "AGAC\n",
      "AGAG\n",
      "AGAU\n",
      "AGCA\n",
      "AGCC\n",
      "AGCG\n",
      "AGCU\n",
      "AGGA\n",
      "AGGC\n",
      "AGGG\n",
      "AGGU\n",
      "AGUA\n",
      "AGUC\n",
      "AGUG\n",
      "AGUU\n",
      "AUAA\n",
      "AUAC\n",
      "AUAG\n",
      "AUAU\n",
      "AUCA\n",
      "AUCC\n",
      "AUCG\n",
      "AUCU\n",
      "AUGA\n",
      "AUGC\n",
      "AUGG\n",
      "AUGU\n",
      "AUUA\n",
      "AUUC\n",
      "AUUG\n",
      "AUUU\n",
      "CAAA\n",
      "CAAC\n",
      "CAAG\n",
      "CAAU\n",
      "CACA\n",
      "CACC\n",
      "CACG\n",
      "CACU\n",
      "CAGA\n",
      "CAGC\n",
      "CAGG\n",
      "CAGU\n",
      "CAUA\n",
      "CAUC\n",
      "CAUG\n",
      "CAUU\n",
      "CCAA\n",
      "CCAC\n",
      "CCAG\n",
      "CCAU\n",
      "CCCA\n",
      "CCCC\n",
      "CCCG\n",
      "CCCU\n",
      "CCGA\n",
      "CCGC\n",
      "CCGG\n",
      "CCGU\n",
      "CCUA\n",
      "CCUC\n",
      "CCUG\n",
      "CCUU\n",
      "CGAA\n",
      "CGAC\n",
      "CGAG\n",
      "CGAU\n",
      "CGCA\n",
      "CGCC\n",
      "CGCG\n",
      "CGCU\n",
      "CGGA\n",
      "CGGC\n",
      "CGGG\n",
      "CGGU\n",
      "CGUA\n",
      "CGUC\n",
      "CGUG\n",
      "CGUU\n",
      "CUAA\n",
      "CUAC\n",
      "CUAG\n",
      "CUAU\n",
      "CUCA\n",
      "CUCC\n",
      "CUCG\n",
      "CUCU\n",
      "CUGA\n",
      "CUGC\n",
      "CUGG\n",
      "CUGU\n",
      "CUUA\n",
      "CUUC\n",
      "CUUG\n",
      "CUUU\n",
      "GAAA\n",
      "GAAC\n",
      "GAAG\n",
      "GAAU\n",
      "GACA\n",
      "GACC\n",
      "GACG\n",
      "GACU\n",
      "GAGA\n",
      "GAGC\n",
      "GAGG\n",
      "GAGU\n",
      "GAUA\n",
      "GAUC\n",
      "GAUG\n",
      "GAUU\n",
      "GCAA\n",
      "GCAC\n",
      "GCAG\n",
      "GCAU\n",
      "GCCA\n",
      "GCCC\n",
      "GCCG\n",
      "GCCU\n",
      "GCGA\n",
      "GCGC\n",
      "GCGG\n",
      "GCGU\n",
      "GCUA\n",
      "GCUC\n",
      "GCUG\n",
      "GCUU\n",
      "GGAA\n",
      "GGAC\n",
      "GGAG\n",
      "GGAU\n",
      "GGCA\n",
      "GGCC\n",
      "GGCG\n",
      "GGCU\n",
      "GGGA\n",
      "GGGC\n",
      "GGGG\n",
      "GGGU\n",
      "GGUA\n",
      "GGUC\n",
      "GGUG\n",
      "GGUU\n",
      "GUAA\n",
      "GUAC\n",
      "GUAG\n",
      "GUAU\n",
      "GUCA\n",
      "GUCC\n",
      "GUCG\n",
      "GUCU\n",
      "GUGA\n",
      "GUGC\n",
      "GUGG\n",
      "GUGU\n",
      "GUUA\n",
      "GUUC\n",
      "GUUG\n",
      "GUUU\n",
      "UAAA\n",
      "UAAC\n",
      "UAAG\n",
      "UAAU\n",
      "UACA\n",
      "UACC\n",
      "UACG\n",
      "UACU\n",
      "UAGA\n",
      "UAGC\n",
      "UAGG\n",
      "UAGU\n",
      "UAUA\n",
      "UAUC\n",
      "UAUG\n",
      "UAUU\n",
      "UCAA\n",
      "UCAC\n",
      "UCAG\n",
      "UCAU\n",
      "UCCA\n",
      "UCCC\n",
      "UCCG\n",
      "UCCU\n",
      "UCGA\n",
      "UCGC\n",
      "UCGG\n",
      "UCGU\n",
      "UCUA\n",
      "UCUC\n",
      "UCUG\n",
      "UCUU\n",
      "UGAA\n",
      "UGAC\n",
      "UGAG\n",
      "UGAU\n",
      "UGCA\n",
      "UGCC\n",
      "UGCG\n",
      "UGCU\n",
      "UGGA\n",
      "UGGC\n",
      "UGGG\n",
      "UGGU\n",
      "UGUA\n",
      "UGUC\n",
      "UGUG\n",
      "UGUU\n",
      "UUAA\n",
      "UUAC\n",
      "UUAG\n",
      "UUAU\n",
      "UUCA\n",
      "UUCC\n",
      "UUCG\n",
      "UUCU\n",
      "UUGA\n",
      "UUGC\n",
      "UUGG\n",
      "UUGU\n",
      "UUUA\n",
      "UUUC\n",
      "UUUG\n",
      "UUUU\n"
     ]
    }
   ],
   "source": [
    "nucleotides = ['A', 'C', 'G', 'U']\n",
    "max_kmer_length = 4\n",
    "\n",
    "kmer_lists = list()\n",
    "# for each length of kmer...\n",
    "for i in range(0, max_kmer_length):\n",
    "    # Create all permutations of that length, and the list they will be stored in\n",
    "    kmer = product(nucleotides, repeat=i+1)\n",
    "    kmer_lists.append(list())\n",
    "    l = kmer_lists[i]\n",
    "    for k in kmer:\n",
    "        # then store permutated values as string in a list\n",
    "        w = ''\n",
    "        for j in range(0, i+1):\n",
    "            w += k[j]\n",
    "        l.append(w)\n",
    "\n",
    "for ix, l in enumerate(kmer_lists):\n",
    "    print(f'list of {ix+1}-mer')\n",
    "    for p in l:\n",
    "        print(p)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Nous allons ensuite créer 4 nouveaux $\\textit{dataframes}$ pour faire le décompte du nombre d'occurence des k-mer dans\n",
    "les séquence de nucléotides, et ultimement pouvoir les 4 présentations."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# Lets start by copying our main dataframe in 4 new dataframes, drop the columns we won't need and put them in a list\n",
    "df_list = list()\n",
    "for i in range(0, max_kmer_length):\n",
    "    df_list.append(data.copy())\n",
    "    df_list[i].drop(labels=['longueur','encoded_classe'], inplace=True, axis=1)\n",
    "    # then lets add the needed columns in each new dataframe\n",
    "    for km in kmer_lists[i]:\n",
    "        df_list[i][km] = pd.Series(range(0, df_list[0].shape[0]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         A\n",
      "id                        \n",
      "AF093014.1/662-809    51.0\n",
      "M14649.1/2015-2169    42.0\n",
      "X53361.2/1206-1368    33.0\n",
      "M86760.1/218-371      39.0\n",
      "X00601.1/3997-4154    47.0\n",
      "...                    ...\n",
      "'U10566.1/72-260\"     60.0\n",
      "'U10567.1/1-190\"      55.0\n",
      "'U22351.1/82-237\"     52.0\n",
      "'U22350.1/54-211\"     52.0\n",
      "AF399707.1/2183-2342  54.0\n",
      "\n",
      "[112 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "# Count the occurence of every k-mer for every sequence\n",
    "for df, kmlist in zip(df_list, kmer_lists):\n",
    "    for km in kmlist:\n",
    "        count = 0\n",
    "        for ix, row in df.iterrows():\n",
    "            # Here we use re.finditer() fct to get all k-mer occurence in a sequence\n",
    "            count = sum(1 for _ in finditer(km, row['sequence']))\n",
    "            df.loc[ix, km] = count\n",
    "        # print(df.loc[:, km])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pycharm-aff07955",
   "language": "python",
   "display_name": "PyCharm (IFT870-TP1)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}